{
 "metadata": {
  "name": "",
  "signature": "sha256:786536921a554b8119030f4cfb6d4a0da4890f0a581fef2a6af51bc55e8a3e08"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Neural-Networks Project\n",
      "\n",
      "## Introduction\n",
      "An essential part of the behavior of humans is their ability to recognize objects. Humans are able to recognize\n",
      "large numbers of other humans, letters, digits, and so on.\n",
      "The object recognition problem can be defined as a labeling problem based on models of known objects. Formally,\n",
      "given an image containing one or more objects of interest (and background) and a set of labels corresponding to a set\n",
      "of models known to the system, the system should assign correct labels to regions, or a set of regions, in the image.\n",
      "\n",
      "## Objective\n",
      "The goal of this project is to build an object recognition system that can pick out and identify objects from an\n",
      "inputted camera image, as shown in Figure 1, based on the registered objects.\n",
      "\n",
      "## System Architecture\n",
      "\n",
      "Input -> Features Extraction -> Classifier -> Voting -> Output\n",
      "\n",
      "## Features Extraction\n",
      "\n",
      "- Use Scale Invariant Feature Transform (SIFT) algorithm [1] to extract features of an image.\n",
      "- SIFT describes image features that have many properties that make them suitable for matching differing images of an object or scene.\n",
      "- The features are invariant to image scaling and rotation, and partially invariant to change in illumination and 3D camera viewpoint.\n",
      "- An important aspect of this approach is that it generates large numbers of features that densely cover the image over the full range of scales and locations.\n",
      "- As shown in Figure 3, given an image, SIFT generates a set of keypoints, each keypoint consists of its location, scale, orientation, and a set of 128 descriptors.\n",
      "- Keypoints are the samples, and their features are the 128 element feature vector (descriptors) for each keypoint.\n",
      "- You can use the implementation of SIFT in VLFeat library [2] or in OpenCV [3].\n",
      "\n",
      "## Requirments\n",
      "\n",
      "- The user must be able to insert an input (image) to the application, and the application has to identify objects on the inputted image.\n",
      "- Using the test images you will test your classifier. And find the performance of your classifier using the Overall Accuracy (OA) and Confusion Matrix.\n",
      "- A comparative study showing the difference in applying the three classification algorithms based on the six evaluation measures mentioned above. Thus, a report template will be provided to you for filling it.\n",
      "- Also, the report must be provided showing the different NN architectures and different parameters you used, and their effect on the training and testing results.\n",
      "\n",
      "### Bouns\n",
      "Conduct a comparative study of different feature extraction algorithms such as SIFT, PCA-SIFT [5], and\n",
      "SURF [6] to show up their effects in improving classification performance of the project\u2019s objective based\n",
      "on the six evaluation measures mentioned above. (A report template will be provided for that)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How to use ipython-notebook?\n",
      "ipython notebook act as client to the server side that's running on your console write now\n",
      "\n",
      "the notebook has cells just like this one ... you can click on this cell to edit it after editing the cell whether it's a \"markdown\" cell or \"code\" cell you can \"evaluate\" or run the cell by pressing \"shift+enter\" or you can use the play button in the icon bar above\n",
      "\n",
      "you can know and change the type of the cell using the dropdown menu from the icon bar above\n",
      "\n",
      "you can evaluate each cell in any order you wish when a cell is not evaluated it has an empty brackets like this on it's left side \"[]\" when the code in this block is running or waiting to be executed the left side indicator will be \"[\\*]\" after finishing executing the cell will have a number indicating it's order in execution \"[1]\" for first cell, \"[2]\" for the second ... etc\n",
      "\n",
      "you can use *TAB* key to auto-complete code\n",
      "\n",
      "you can add *?* then evaluate the cell to get the documentation for example: \"np.array?\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 01:\n",
      "listing the files of training and testing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os,sys\n",
      "import numpy as np\n",
      "import cv2\n",
      "from os import listdir\n",
      "from os.path import isfile, join\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TRAINING_PATH = \"Data set/Training/\"\n",
      "TESTING_PATH = \"Data set/Testing/\"\n",
      "TRAINING_FILES = [f for f in listdir(TRAINING_PATH) if isfile(join(TRAINING_PATH, f))]\n",
      "TESTING_FILES = [f for f in listdir(TESTING_PATH) if isfile(join(TESTING_PATH, f))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 02:\n",
      "loading images and labels into dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Labels_Index = {\n",
      "                \"Cat\":        np.array([1.0,0.0,0.0,0.0,0.0]),\n",
      "                \"Laptop\":     np.array([0.0,1.0,0.0,0.0,0.0]),\n",
      "                \"Apple\":      np.array([0.0,0.0,1.0,0.0,0.0]),\n",
      "                \"Car\":        np.array([0.0,0.0,0.0,1.0,0.0]),\n",
      "                \"Helicopter\": np.array([0.0,0.0,0.0,0.0,1.0])\n",
      "                }\n",
      "\n",
      "#given the word this function returns the onehot vector label\n",
      "def getLabelIndex(word):\n",
      "    if word in Labels_Index:\n",
      "        return Labels_Index[word]\n",
      "    else:\n",
      "        return np.zeros(5)\n",
      "\n",
      "#given the onehot vector label this function returns the word\n",
      "def getLabelWord(index):\n",
      "    for key in Labels_Index.keys():\n",
      "        if index == Labels_Index[key]:\n",
      "            return key\n",
      "    return \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#function given filename it returns a list of labels associated with this file\n",
      "#it depend on filename that  contains the classes of this image\n",
      "def getImageLabels(image_filename):\n",
      "    result = []\n",
      "    if image_filename.find(\"Cat\") != -1:\n",
      "        result.append(Labels_Index[\"Cat\"])\n",
      "    \n",
      "    if image_filename.find(\"Laptop\") != -1:\n",
      "        result.append(Labels_Index[\"Laptop\"])\n",
      "        \n",
      "    if image_filename.find(\"Apple\") != -1:\n",
      "        result.append(Labels_Index[\"Apple\"])\n",
      "        \n",
      "    if image_filename.find(\"Car\") != -1:\n",
      "        result.append(Labels_Index[\"Car\"])\n",
      "        \n",
      "    if image_filename.find(\"Helicopter\") != -1:\n",
      "        result.append(Labels_Index[\"Helicopter\"])\n",
      "        \n",
      "    return result\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Layout:\n",
      "- Data = Dictionary or map of data\n",
      "- Key = File name\n",
      "- Value = Dictionary {\"image\": numpy array of image data, \"labels\": list of onehot vectors that represents the labels associated with this image\n",
      "\n",
      "### How to Iterate over Data?\n",
      "```\n",
      "for filename in TrainingData:\n",
      "        image = TrainingData[filename][\"image\"]\n",
      "        labels = TrainingData[filename][\"labels\"]\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dictionary that contains the training data\n",
      "TrainingData = {}\n",
      "for image in TRAINING_FILES:\n",
      "    image_filename = join(TRAINING_PATH, image)\n",
      "    TrainingData[image_filename] = {\"image\": cv2.imread(image_filename),\n",
      "                                     \"labels\": getImageLabels(image_filename)}\n",
      "#dictionary that contains the testing data\n",
      "TestingData = {}\n",
      "for image in TESTING_FILES:\n",
      "    image_filename = join(TESTING_PATH, image)\n",
      "    TestingData[image_filename] = {\"image\": cv2.imread(image_filename),\n",
      "                                    \"labels\": getImageLabels(image_filename)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function to View the image given it's image matrix/data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def view_image(img):\n",
      "    cv2.startWindowThread()\n",
      "    cv2.namedWindow(\"preview\")\n",
      "    cv2.imshow(\"preview\" ,img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get SIFT Features and a function to draw and view the features on the image"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SIFT = cv2.SIFT()\n",
      "def getKeyPoints(img):\n",
      "    return SIFT.detect(img,None)\n",
      "\n",
      "def viewSIFTPoints(img,points):\n",
      "    view_image(cv2.drawKeypoints(img,points))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}